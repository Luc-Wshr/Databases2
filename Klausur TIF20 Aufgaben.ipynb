{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41064b1f",
   "metadata": {},
   "source": [
    "Aufgabe 1: [15/120 Punkte] Nenne 5 **verschiedene** Anwendungen wo Key-Value-Datenbanken Vorteile gegenüber Relationalen Datenbanken haben, und beschreibe spezifisch (aber dennoch stichwortartig) für jeden Fall, was genau der jeweilige Vorteil ist (und: was potentielle Nachteile sind)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12a0651-cfcb-4f44-af97-f82bf1e2ffa7",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Echtzeit-Datenverarbeitung: Key-Value-Datenbanken sind aufgrund ihrer in-memory-Architektur besonders gut geeignet für die Verarbeitung von Echtzeit-Daten, da sie schnelle Antwortzeiten bieten. \n",
    "\n",
    "Session-Management: Key-Value-Datenbanken können verwendet werden, um Benutzer-Sessions in Web-Anwendungen zu speichern und abzurufen. Dies kann nützlich sein, um Benutzer-Informationen während ihrer Sitzung zu speichern und zu verfolgen. \n",
    "\n",
    "Verteilte Systeme: Key-Value-Datenbanken eignen sich gut für verteilte Systeme, da sie leicht zu skalieren sind und schnellen Zugriff auf Daten bieten.\n",
    "\n",
    "\n",
    "Speicherung von unstrukturierten Daten: Key-Value-Datenbanken sind in der Lage, beliebige Arten von Daten zu speichern, ohne dass sie in einem vordefinierten Schema strukturiert wer\n",
    "\n",
    "Caching: Key-Value-Datenbanken eignen sich besonders gut für das Caching von Daten, da sie schnellen Zugriff auf Daten ermöglichen und hohe Durchsatzraten unterstützen. Dies kann bei der Verbesserung der Leistung von Anwendungen hilfreich sein, die häufig auf dieselben Daten zugreifen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa609eeb",
   "metadata": {},
   "source": [
    "Aufgabe 2: [15/120 Punkte] erkläre was denn nun wirklich die Hauptunterschiede zwischen einem Data Warehouse und einem Data Lake sind und gib Beispiele für Anwendungen in denen entweder ein Data Warehouse oder ein Data Lake die bessere Wahl ist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a613af9-5931-4a4b-b772-60569a6823ad",
   "metadata": {},
   "source": [
    "In einem Data Lake könnnen im gegenzug zu einem Datawarehouse unstrukturierte Daten gespeichert werden. \n",
    "In einem DL können Daten in ihrem Rohzustand abgespeichert werden. \n",
    "In einem DL können aus verschieden Datenquellen daten bezogen werden.\n",
    "Ein DataLake eigenen sich besonders gut für analysen\n",
    "\n",
    "Data Lake:\n",
    "-rohe Datenstruktur\n",
    "-Zweck/Schema der Daten noch nicht festgelegt\n",
    "-Anwender: Data Scientists\n",
    "-Gut zugänglich und schnell zu aktualisieren\n",
    "Data Warehouse:\n",
    "-Daten sind verarbeitet\n",
    "-Zweck/Schema der Daten in Formate, Strukturen überführt\n",
    "-Anwender: Business Analysten\n",
    "-Teuer und Kompliziert änderungen vorzunehmen\n",
    "\n",
    "Beispeile:\n",
    "Data Lake:\n",
    "-Gesundheitswesen: erlauben Kombination aus unstrukturierten und strukturierten Daten eignet sich mehr\n",
    "-Transportwesen: Anhand von Prognosefunktionen Vorhesagen treffen\n",
    "-Bildungswesen: oft umfangreiche, kaum verarbeitete Rohdaten, Abrechnugsprozess, Daten zu Noten .etc\n",
    "Data Warehouse:\n",
    "-Einzelhandel: enthält Daten von Kassen, Mailinglisten, Websites \n",
    "-Finanzwesen: So strukturiert, dass für Alle im Unternehmen genutzt werden kann, kosteneffizient\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9a4491",
   "metadata": {},
   "source": [
    "Aufgabe 3: [15/120 Punkte] im folgenden Code hat sich der Fehlerteufel eingeschlichen. Finde die 5 Fehler (10 Punkte), und beschreibe stichwortartig, was der Code denn tun würde, wenn keine Fehler drin wären. (5 Punkte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6334810e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bson.son import SON # import von pymongo fehlt ,from pymongo import MongoClient \n",
    "client = MongoClient(\"localhost\", 27017)\n",
    "connect = client[\"database\"],[\"collection\"]#Database erstellung und angabe von collection ist falsch\n",
    "+\n",
    "pipe2 = [ { '$mismatch' : { 'origin' : 'ATL', # aggregation heißt match -> mismatch gibt es nicht\n",
    "                         'dest' : 'BOS',\n",
    "                         'dayofweek' : 3\n",
    "                       }\n",
    "          },\n",
    "          { '$group' : { '_id' : { 'origin' : '$origin',\n",
    "                                   'destination' : '$dest'\n",
    "                                 },\n",
    "                         'Failure' : { '$sum' : { '$cond' : [{ '$eq' : ['$cancelled', 1]}, 1, 0 ]} },\n",
    "                         'Success' : { '$sum' : { '$cond' : [{ '$eq' : ['$cancelled', 0]}, 1, 0 ]} },\n",
    "                         'Total' : { '$sum' : 1 }\n",
    "                        }\n",
    "           },\n",
    "           { '$project' : { 'Failure' : 1,\n",
    "                            'Success' : 1,\n",
    "                            'Total' : 1,\n",
    "                            'FailPercent' : { '$divide' : [ '$Failure', '$Total' ] }\n",
    "                          }\n",
    "           },\n",
    "           # im SON-Statement ist kein Fehler, das gehoert so \n",
    "           { '$sort' : SON([('_id.origin', 1), ('_id.destination', 1 )]) }\n",
    "         \n",
    "\n",
    "result = connection.aggregate(pipeline=pipe2) #hier muss nur pipe2 eingegeben werden , und unsere connection heißt nicht connection sondern connect\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdd2f31-0d4d-407b-8000-6cbb85f22934",
   "metadata": {
    "tags": []
   },
   "source": [
    "Fehler sind als Kommentar im code angegeben\n",
    "\n",
    "Beschreibung von code:\n",
    "zuerst werden daten von einer bson datei von einer mongodb \"gelesen\"\n",
    "danach wird eine pipeline aufgestellt in welcher alles angezeigt werden soll welches nicht die angegebene Origin, dest und dayofweek enthält\n",
    "diese gefundenen einträge werden dann gruppiert und es wird gezählt wie viel Einträge sich in Failure, Succes und Total beinhalten,  anschließend mit projekt ausgegeben\n",
    "zum schluss wird noch nach der origin und destination aufsteigend sortiert. \n",
    "die aggregatin wird nun in eine neue variable result gespeicht und diese dann mit print ausgegeben. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae06e21",
   "metadata": {},
   "source": [
    "Aufgabe 4: [15/120 Punkte] Erkläre was lazy evaluation ist an Hand von 2 in den Vorlesungen behandelten Technologien/Ansätzen (1 Lazy, eine nicht lazy) - und erläutere, was die Auswirkungen in der Praxis sind."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8ff727-08a9-4ca5-9fc4-4c3ad97763b0",
   "metadata": {},
   "source": [
    "lazy evalutation ist, wenn die Ausführung erst bei geschieht wenn dieses gewünscht ist. \n",
    "z.B. ist spark lazy da es ohne den show() befehl die neu angegebene variable nicht \"schreibt\"\n",
    "\n",
    "\n",
    "nicht lazy ist z.B. Redis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e322834c",
   "metadata": {},
   "source": [
    "Aufgabe 5: [40/120 Punkte]\n",
    "    In Moodle findest Du Super-Markt Daten. Werte diese in Spark aus, und finde heraus:\n",
    "    \n",
    "    1) wie viele Einkäufe wurden von Frauen, bzw von Männern getätigt?\n",
    "    2) wie viel Umsatz wurde an den 3 Standorten jeweils getätigt - gib diesen zusammen mit dem NAMEN des jeweiligen Standorts aus\n",
    "    3) welche Bezahlart die höchste durchschnittliche User-Satisfaction hat\n",
    "    \n",
    "Exportiere die Ergebnisse von Teilaufgabe 3 als CSV-Datei - stelle dabei sicher, dass unabhängig von der Größe des Datensatzes nur 1 einzige CSV-Datei generiert wird.\n",
    "\n",
    "Beschreibe für jede der Teilaufgaben wie Du die Daten dazu aufbereiten würdest (Stichwort: Designentscheidungen)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad47e29b-d62e-479e-b96a-9c5bbc917ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create SparkSession \n",
    "spark = SparkSession.builder \\\n",
    "      .master(\"local[1]\") \\\n",
    "      .appName(\"sales\") \\\n",
    "      .getOrCreate() \n",
    "\n",
    "# Einlesen von Dateien in Spark, Datei Typ einfach Anpassen\n",
    "#Datei wurde als csv gespeichert und kann jetzt hinzugefügt werden, \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed88c4fc-7687-4839-90e1-df4669af5563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://localhost:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[1]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>sales</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f418608c2b0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fa6963-fba9-4339-a4bb-08ba5dd8dccf",
   "metadata": {},
   "source": [
    "Bitte den Zusatzpunkt beachten für herausfinden wie man die Datei als csv speichern kann ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3170dc2c-9273-4a43-a93c-be4a0ce93f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+---------+-------------+------+----------------------+----------+--------+-------+--------+---------+-----+-----------+------+-----------------------+------------+------+\n",
      "|Invoice ID |Branch|City     |Customer type|Gender|Product line          |Unit price|Quantity|Tax 5% |Total   |Date     |Time |Payment    |cogs  |gross margin percentage|gross income|Rating|\n",
      "+-----------+------+---------+-------------+------+----------------------+----------+--------+-------+--------+---------+-----+-----------+------+-----------------------+------------+------+\n",
      "|750-67-8428|A     |Yangon   |Member       |Female|Health and beauty     |74.69     |7       |26.1415|548.9715|1/5/2019 |13:08|Ewallet    |522.83|4.761904762            |26.1415     |9.1   |\n",
      "|226-31-3081|C     |Naypyitaw|Normal       |f     |Electronic accessories|15.28     |5       |3.82   |80.22   |3/8/2019 |10:29|Cash       |76.4  |4.761904762            |3.82        |9.6   |\n",
      "|631-41-3108|A     |null     |Normal       |Male  |Home and lifestyle    |46.33     |7       |16.2155|340.5255|3/3/2019 |13:23|credit card|324.31|4.761904762            |16.2155     |7.4   |\n",
      "|123-19-1176|A     |Yangon   |Member       |male  |Health and beauty     |58.22     |8       |23288  |489048  |1/27/2019|20:33|Ewallet    |465.76|4.761904762            |23288       |8.4   |\n",
      "|373-73-7910|A     |Yangon   |Normal       |Male  |Sports and travel     |86.31     |7       |30.2085|634.3785|2/8/2019 |10:37|ewallet    |604.17|4.761904762            |30.2085     |5.3   |\n",
      "|699-14-3026|C     |Naypyitaw|Normal       |Male  |Electronic accessories|85.39     |7       |29.8865|627.6165|3/25/2019|18:30|Ewallet    |597.73|4.761904762            |29.8865     |4.1   |\n",
      "|355-53-5943|A     |Yangon   |Member       |f     |Electronic accessories|68.84     |6       |20652  |433692  |2/25/2019|14:36|Ewallet    |413.04|4.761904762            |20652       |5.8   |\n",
      "|315-22-5665|C     |null     |Normal       |Female|Home and lifestyle    |73.56     |10      |36.78  |772.38  |2/24/2019|11:38|Ewallet    |735.6 |4.761904762            |36.78       |8     |\n",
      "|665-32-9167|A     |Yangon   |Member       |f     |Health and beauty     |36.26     |2       |3626   |76146   |1/10/2019|17:15|Creditcard |72.52 |4.761904762            |3626        |7.2   |\n",
      "|692-92-5582|B     |Mandalay |Member       |Female|Food and beverages    |54.84     |3       |8226   |172746  |2/20/2019|13:27|creditcard |164.52|4.761904762            |8226        |5.9   |\n",
      "|351-62-0822|B     |Mandalay |Member       |Female|Fashion accessories   |14.48     |4       |2896   |60816   |2/6/2019 |18:07|Ewallet    |57.92 |4.761904762            |2896        |4.5   |\n",
      "|529-56-3974|B     |null     |Member       |m     |Electronic accessories|25.51     |4       |5102   |107142  |3/9/2019 |17:03|cash       |102.04|4.761904762            |5102        |6.8   |\n",
      "|365-64-0515|A     |Yangon   |Normal       |Female|Electronic accessories|46.95     |5       |11.7375|246.4875|2/12/2019|10:25|Ewallet    |234.75|4.761904762            |11.7375     |7.1   |\n",
      "|252-56-2699|A     |null     |Normal       |m     |Food and beverages    |43.19     |10      |21595  |453495  |2/7/2019 |16:48|Ewallet    |431.9 |4.761904762            |21595       |8.2   |\n",
      "|829-34-3910|A     |Yangon   |Normal       |Female|Health and beauty     |71.38     |10      |35.69  |749.49  |3/29/2019|19:21|Cash       |713.8 |4.761904762            |35.69       |5.7   |\n",
      "|299-46-1805|B     |Mandalay |Member       |Female|Sports and travel     |93.72     |6       |28116  |590436  |1/15/2019|16:19|cash       |562.32|4.761904762            |28116       |4.5   |\n",
      "|656-95-9349|A     |Yangon   |Member       |Female|Health and beauty     |68.93     |7       |24.1255|506.6355|3/11/2019|11:03|Creditcard |482.51|4.761904762            |24.1255     |4.6   |\n",
      "|765-26-6951|A     |null     |Normal       |Male  |Sports and travel     |72.61     |6       |21783  |457443  |1/1/2019 |10:39|Credit card|435.66|4.761904762            |21783       |6.9   |\n",
      "|329-62-1586|A     |Yangon   |Normal       |m     |Food and beverages    |54.67     |3       |8.2005 |172.2105|1/21/2019|18:00|Creditcard |164.01|4.761904762            |8.2005      |8.6   |\n",
      "|319-50-3348|B     |Mandalay |Normal       |female|Home and lifestyle    |40.3      |2       |4.03   |84.63   |3/11/2019|15:30|Ewallet    |80.6  |4.761904762            |4.03        |4.4   |\n",
      "+-----------+------+---------+-------------+------+----------------------+----------+--------+-------+--------+---------+-----+-----------+------+-----------------------+------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Daten ein csv einlesen\n",
    "sales=spark.read.csv(\"/home/student/Downloads/supermarket_sales.csv\",header=True)\n",
    "sales.show(truncate=False)\n",
    "# Schema anzeigen lassen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "57e1003e-e8cc-4836-842d-3cfdcb0f285e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Invoice ID: string (nullable = true)\n",
      " |-- Branch: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Customer type: string (nullable = true)\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- Product line: string (nullable = true)\n",
      " |-- Unit price: string (nullable = true)\n",
      " |-- Quantity: string (nullable = true)\n",
      " |-- Tax 5%: string (nullable = true)\n",
      " |-- Total: string (nullable = true)\n",
      " |-- Date: string (nullable = true)\n",
      " |-- Time: string (nullable = true)\n",
      " |-- Payment: string (nullable = true)\n",
      " |-- cogs: string (nullable = true)\n",
      " |-- gross margin percentage: string (nullable = true)\n",
      " |-- gross income: string (nullable = true)\n",
      " |-- Rating: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sales.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1bfc770b-3645-4891-a256-11c88bb5f997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|Gender|\n",
      "+------+\n",
      "|Female|\n",
      "|     f|\n",
      "|  Male|\n",
      "|  male|\n",
      "|  Male|\n",
      "|  Male|\n",
      "|     f|\n",
      "|Female|\n",
      "|     f|\n",
      "|Female|\n",
      "|Female|\n",
      "|     m|\n",
      "|Female|\n",
      "|     m|\n",
      "|Female|\n",
      "|Female|\n",
      "|Female|\n",
      "|  Male|\n",
      "|     m|\n",
      "|female|\n",
      "+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# zuerst mal die Gender column ausgeben um heraus zu finden wie viele m und f da drin sind\n",
    "import pyspark.sql.functions as F\n",
    "gender= sales.select(F.col(\"Gender\"))\n",
    "gender.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4bdfa157-dcc3-41bc-ae97-56301f140dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|Gender_lower|\n",
      "+------------+\n",
      "|      female|\n",
      "|           f|\n",
      "|        male|\n",
      "|        male|\n",
      "|        male|\n",
      "|        male|\n",
      "|           f|\n",
      "|      female|\n",
      "|           f|\n",
      "|      female|\n",
      "|      female|\n",
      "|           m|\n",
      "|      female|\n",
      "|           m|\n",
      "|      female|\n",
      "|      female|\n",
      "|      female|\n",
      "|        male|\n",
      "|           m|\n",
      "|      female|\n",
      "+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Design entscheidung: alles 1. lowercase setzen und der column jetzt den namen \"Gender_lower\" geben\n",
    "lower_words=gender.select(F.lower(F.col(\"Gender\")).alias(\"Gender_lower\"))\n",
    "lower_words.show()\n",
    "lower_words.count()\n",
    "#gezählt wie viel einträge es denn überhaupt sind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d80f420a-add2-4551-8d92-d4c7a5eaf2d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "141"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Anzeigen wie viele käufer male waren, hirbei wurde nach dem anfangsbuchstaben m gefiltert \n",
    "male = lower_words.filter(F.col(\"Gender_lower\").rlike(\"^m\"))\n",
    "#filtered_df.show()\n",
    "male.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c090917a-63e8-4d7f-aa72-a6ffe3194a97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ausgeben wie viel frauen eingekauft haben \n",
    "female = lower_words.filter(F.col(\"Gender_lower\").rlike(\"^f\"))\n",
    "#filtered_df.show()\n",
    "female.count()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41cf6d79-7842-41df-bc4f-d062a47fa0b7",
   "metadata": {},
   "source": [
    "Teilaufgabe 2 \n",
    "wie viel Umsatz wurde an den 3 Standorten jeweils getätigt - gib diesen zusammen mit dem NAMEN des jeweiligen Standorts aus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5f7d0d37-e3be-4461-a218-cb41d7dc3047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------+\n",
      "|     City|gross income|\n",
      "+---------+------------+\n",
      "|   Yangon|     26.1415|\n",
      "|Naypyitaw|        3.82|\n",
      "|     null|     16.2155|\n",
      "|   Yangon|       23288|\n",
      "|   Yangon|     30.2085|\n",
      "|Naypyitaw|     29.8865|\n",
      "|   Yangon|       20652|\n",
      "|     null|       36.78|\n",
      "|   Yangon|        3626|\n",
      "| Mandalay|        8226|\n",
      "| Mandalay|        2896|\n",
      "|     null|        5102|\n",
      "|   Yangon|     11.7375|\n",
      "|     null|       21595|\n",
      "|   Yangon|       35.69|\n",
      "| Mandalay|       28116|\n",
      "|   Yangon|     24.1255|\n",
      "|     null|       21783|\n",
      "|   Yangon|      8.2005|\n",
      "| Mandalay|        4.03|\n",
      "+---------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Liste der city und gross income spalten darstellen, da die 3 shops in den 3 verschiedenen Städten sind\n",
    "umsatz=sales.select(F.col(\"City\"),F.col(\"gross income\"))\n",
    "umsatz.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2fd6c27f-9922-4c9b-8bd1-ebb7c346d56d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- City: string (nullable = true)\n",
      " |-- gross income: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- City: string (nullable = true)\n",
      " |-- gross income: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "umsatz.printSchema()\n",
    "#cross income in einen float ändern, da es aktuell noch ein string ist \n",
    "import pyspark.sql.types as T\n",
    "\n",
    "cross_type = umsatz.withColumn(\"gross income\", F.col(\"gross income\").cast(T.FloatType())) \n",
    "             \n",
    "cross_type.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "71684102-e3c0-4038-a07d-0d4c14a29009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------+\n",
      "|     City|gross income|\n",
      "+---------+------------+\n",
      "|   Yangon|     26.1415|\n",
      "|Naypyitaw|        3.82|\n",
      "|     null|     16.2155|\n",
      "|   Yangon|     23288.0|\n",
      "|   Yangon|     30.2085|\n",
      "|Naypyitaw|     29.8865|\n",
      "|   Yangon|     20652.0|\n",
      "|     null|       36.78|\n",
      "|   Yangon|      3626.0|\n",
      "| Mandalay|      8226.0|\n",
      "| Mandalay|      2896.0|\n",
      "|     null|      5102.0|\n",
      "|   Yangon|     11.7375|\n",
      "|     null|     21595.0|\n",
      "|   Yangon|       35.69|\n",
      "| Mandalay|     28116.0|\n",
      "|   Yangon|     24.1255|\n",
      "|     null|     21783.0|\n",
      "|   Yangon|      8.2005|\n",
      "| Mandalay|        4.03|\n",
      "+---------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cross_type.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "393ad939-adf7-4ff8-a1a7-aced101491ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------+\n",
      "|  City|gross income|\n",
      "+------+------------+\n",
      "|Yangon|     26.1415|\n",
      "|Yangon|     23288.0|\n",
      "|Yangon|     30.2085|\n",
      "|Yangon|     20652.0|\n",
      "|Yangon|      3626.0|\n",
      "|Yangon|     11.7375|\n",
      "|Yangon|       35.69|\n",
      "|Yangon|     24.1255|\n",
      "|Yangon|      8.2005|\n",
      "|Yangon|        8.64|\n",
      "|Yangon|     21036.0|\n",
      "|Yangon|      8767.0|\n",
      "|Yangon|     11.2005|\n",
      "|Yangon|      9658.0|\n",
      "|Yangon|     15655.0|\n",
      "|Yangon|     27396.0|\n",
      "|Yangon|     11.1475|\n",
      "|Yangon|      4434.0|\n",
      "|Yangon|       35.84|\n",
      "|Yangon|     36175.0|\n",
      "+------+------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "DataFrame[gross income: float, sum(gross income): double]\n"
     ]
    }
   ],
   "source": [
    "#Jetz nach den Unterschiedlichen City Einträgen gruppieren und die gross income werte zusammen zählen, ich weiß ist hässlich so aber die zeit ist im nacken... :/\n",
    "#Die null einträge werden aus design entscheidung nicht mit gewertet\n",
    "Yangon=cross_type.filter(F.col(\"City\").rlike(\"^Yangon\"))\n",
    "Yangon.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "47cce498-8064-40cf-8245-b5821d3f2edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|gross income|\n",
      "+------------+\n",
      "|     26.1415|\n",
      "|     23288.0|\n",
      "|     30.2085|\n",
      "|     20652.0|\n",
      "|      3626.0|\n",
      "|     11.7375|\n",
      "|       35.69|\n",
      "|     24.1255|\n",
      "|      8.2005|\n",
      "|        8.64|\n",
      "|     21036.0|\n",
      "|      8767.0|\n",
      "|     11.2005|\n",
      "|      9658.0|\n",
      "|     15655.0|\n",
      "|     27396.0|\n",
      "|     11.1475|\n",
      "|      4434.0|\n",
      "|       35.84|\n",
      "|     36175.0|\n",
      "+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#summieren der werte\n",
    "Yangon_sum=Yangon.select(F.col(\"gross income\"))\n",
    "Yangon_sum.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "86b38ffb-9ea4-4cf1-97ff-a7c48061b110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|sum(gross income)|\n",
      "+-----------------+\n",
      "|689094.2360014915|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Umsatz in Yangon \n",
    "Yangon_sum=Yangon.select(F.sum(\"gross income\"))\n",
    "Yangon_sum.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1ca7b44d-f783-4e77-9558-c1bf7a082fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------+\n",
      "|     City|gross income|\n",
      "+---------+------------+\n",
      "|Naypyitaw|        3.82|\n",
      "|Naypyitaw|     29.8865|\n",
      "|Naypyitaw|      3406.0|\n",
      "|Naypyitaw|     21968.0|\n",
      "|Naypyitaw|      5611.0|\n",
      "|Naypyitaw|       39.48|\n",
      "|Naypyitaw|     41315.0|\n",
      "|Naypyitaw|       31.99|\n",
      "|Naypyitaw|      0.7715|\n",
      "|Naypyitaw|     34392.0|\n",
      "|Naypyitaw|      9183.0|\n",
      "|Naypyitaw|      3711.0|\n",
      "|Naypyitaw|     16719.0|\n",
      "|Naypyitaw|      3347.0|\n",
      "|Naypyitaw|       44.74|\n",
      "|Naypyitaw|       31.06|\n",
      "|Naypyitaw|     22773.0|\n",
      "|Naypyitaw|     20825.0|\n",
      "|Naypyitaw|     22068.0|\n",
      "|Naypyitaw|     39155.0|\n",
      "+---------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Naypyitaw=cross_type.filter(F.col(\"City\").rlike(\"^Naypyitaw\"))\n",
    "Naypyitaw.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "efc92088-605f-4a2c-ba1b-55326b92efd5",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "col should be Column",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[94], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Umsatz in Naypyitaw\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m Naypyitaw_sum\u001b[38;5;241m=\u001b[39m\u001b[43mNaypyitaw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgross income\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwithColumn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNaypyitaw\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m Naypyitaw_sum\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[0;32m/opt/apache-spark/python/pyspark/sql/dataframe.py:3035\u001b[0m, in \u001b[0;36mDataFrame.withColumn\u001b[0;34m(self, colName, col)\u001b[0m\n\u001b[1;32m   3005\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3006\u001b[0m \u001b[38;5;124;03mReturns a new :class:`DataFrame` by adding a column or replacing the\u001b[39;00m\n\u001b[1;32m   3007\u001b[0m \u001b[38;5;124;03mexisting column that has the same name.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3032\u001b[0m \n\u001b[1;32m   3033\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3034\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(col, Column):\n\u001b[0;32m-> 3035\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcol should be Column\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   3036\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jdf\u001b[38;5;241m.\u001b[39mwithColumn(colName, col\u001b[38;5;241m.\u001b[39m_jc), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msparkSession)\n",
      "\u001b[0;31mTypeError\u001b[0m: col should be Column"
     ]
    }
   ],
   "source": [
    "# Umsatz in Naypyitaw\n",
    "Naypyitaw_sum=Naypyitaw.select(F.sum(\"gross income\"))\n",
    "Naypyitaw_sum.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3d3779e5-43df-42e8-ab84-933ce0561cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+\n",
      "|    City|gross income|\n",
      "+--------+------------+\n",
      "|Mandalay|      8226.0|\n",
      "|Mandalay|      2896.0|\n",
      "|Mandalay|     28116.0|\n",
      "|Mandalay|        4.03|\n",
      "|Mandalay|     13197.0|\n",
      "|Mandalay|        3.32|\n",
      "|Mandalay|      1676.0|\n",
      "|Mandalay|       22.09|\n",
      "|Mandalay|     23.5325|\n",
      "|Mandalay|     33512.0|\n",
      "|Mandalay|     12048.0|\n",
      "|Mandalay|      4336.0|\n",
      "|Mandalay|     20736.0|\n",
      "|Mandalay|     18792.0|\n",
      "|Mandalay|     25.5105|\n",
      "|Mandalay|      9.0045|\n",
      "|Mandalay|      3574.0|\n",
      "|Mandalay|      1616.0|\n",
      "|Mandalay|     24.7815|\n",
      "|Mandalay|     15148.0|\n",
      "+--------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Mandalay=cross_type.filter(F.col(\"City\").rlike(\"^Mandalay\"))\n",
    "Mandalay.show()\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "70218e86-1c62-4283-b435-4ac320b6787c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|sum(gross income)|\n",
      "+-----------------+\n",
      "|951144.4380013943|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Umsatz in mandalay\n",
    "Mandalay_sum=Mandalay.select(F.sum(\"gross income\"))\n",
    "Mandalay_sum.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9969cb63-bbd9-49f6-b95d-d38711d9b336",
   "metadata": {},
   "source": [
    "Teilaufgabe 3 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5335ef0f",
   "metadata": {
    "tags": []
   },
   "source": [
    "Aufgabe 6: [20/60 Punkte] Ein regionales Unternehmen hat ein großes Investment durch eine Venture Capital Firma bekommen, und möchte jetzt international expandieren. \n",
    "\n",
    "Euer Auftrag ist es das Unternehmen zum Thema \"Datenbanken\" (die für die internationale Expansion benötig werden) zu beraten.\n",
    "\n",
    "Das bisherige Hauptprodukt des Unternehmens sind mit Schokolade überzogene Fruchtgummis. Im Zuge der Expansion möchte das Unternehmen aber auch gleichzeitig neue Produkte einführen, bzw an regionale Geschmäcker anpassen. Dadurch, dass die Expansion überall gleichzeitig erfolgen soll, sind am Anfang wenig Möglichkeiten direkt Kundenumfragen zu machen - statt dessen soll die Resonanz auf Marketingcampagnen und die Interaktion mit der jeweiligen Landeswebseite genutzt werden, um lokale \"Geschmäcker\" und damit das Potential für weitere Produkte zu erforschen.\n",
    "\n",
    "Der bisher einzige Vertriebskanal ist eine Online-Präsenz, zumindest anfänglich soll dies auch so bleiben, jedoch mit potentiell separaten Webseiten für verschiedene Länder/Regionen. Hierzu besteht aber noch keine fest definierte Strategie, der Unternehmer würde von Euch auch gerne wissen, was für Möglichkeiten, Vor- und Nachteile, und Risiken verschiedener Ansätze (aus Sicht der Nutzung von Datenbanken) sind.\n",
    "\n",
    "Erläutere **stichwortartig**:\n",
    "\n",
    "1) welche Technologien in welchem Bereich eingesetzt werden, und warum\n",
    "2) was für Strategien, bzw Tools Ihr einsetzen wollt um \n",
    "    - die schon vorhandenen Daten zu migrieren\n",
    "    - neue Daten mit den alten zu verbinden\n",
    "    - benötigte Daten zu erhalten\n",
    "3) welche Strategien sich anbieten für das Reporting, die Datenhaltung, Backups etc.\n",
    "4) was die Auswirkungen verschiedener Expansionsstrategien (z.B. Marketing, Website etc) auf die Nutzung/Nützlichkeit/Performance der Datenbank(en) wäre \n",
    "5) Ob es \"Bottlenecks\" oder mit (hohem) Risiko verbundene Datenbank-Komponenten gibt, und wie man damit in der Praxis umgehen soll\n",
    "\n",
    "(wirklich nur stichwortartig, keine Romane!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5047daf4-6fef-44e6-9c6f-a23048eabe16",
   "metadata": {},
   "source": [
    "1) Um das Feedback einzuholen wäre es denkbar, auf der jeweiligen landeswebseite ein kafka system zu implementieren, so könnte in Echtzeit mittels Eventstreaming der markt analysiert werden. Hierbei ist kafka in verbindung mit Redis gut geeignet. Diese Daten können anschließen bereinigt auf z.B. eine MongoDB geladen werden. \n",
    "Um immer die aktuellen Daten über die Geschmäcker bereit zu haben könnte ein Airflow initialisiert werden, welche in einem bestimmten Intervall die gewünschten Abfragen auf die DB automatisch durchführt\n",
    "\n",
    "2)Die Vorhanden Daten würde ich mit Redis bereinigen und diese dann in die zentrale DB speichern\n",
    "\n",
    "3) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
